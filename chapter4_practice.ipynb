{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['おいしい', 'ビール', 'を', '飲む'],\n",
       " ['コーヒー', 'を', '飲む'],\n",
       " ['おいしい', 'クラフト', 'ビール', 'を', '買う']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "sentences = [\n",
    "    'おいしいビールを飲む', 'コーヒーを飲む', 'おいしいクラフトビールを買う'\n",
    "]\n",
    "\n",
    "words_list = []\n",
    "for sentence in sentences:\n",
    "    words_list.append(t.tokenize(sentence, wakati=True))\n",
    "words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['おいしい', 'ビール', 'を', '飲む', 'コーヒー', 'クラフト', '買う']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = []\n",
    "for words in words_list:\n",
    "    for word in words:\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 0, 0, 0], [0, 0, 1, 1, 1, 0, 0], [1, 1, 1, 0, 0, 1, 1]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_list = []\n",
    "for words in words_list:\n",
    "    bag_of_words = []\n",
    "    for unique_word in unique_words:\n",
    "        num = words.count(unique_word)\n",
    "        bag_of_words.append(num)\n",
    "    bow_list.append(bag_of_words)\n",
    "bow_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.28768207245178085,\n",
       " 0.28768207245178085,\n",
       " 0.0,\n",
       " 0.28768207245178085,\n",
       " 0.6931471805599453,\n",
       " 0.6931471805599453,\n",
       " 0.6931471805599453]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "num_of_sentences = len(sentences)\n",
    "idf = []\n",
    "for i in range(len(unique_words)):\n",
    "    count = 0\n",
    "    for bow in bow_list:\n",
    "        if bow[i] > 0:\n",
    "            count += 1\n",
    "    idf.append(log((num_of_sentences + 1) / (count + 1)))\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.42922735748392693,\n",
       " 0.5643823935199818,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = bow_list[1]\n",
    "num_of_words = sum(bow)\n",
    "tfidf = []\n",
    "for i, value in enumerate(bow):\n",
    "    tf = value / num_of_words\n",
    "    tfidf.append(tf * (idf[i] + 1))\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['__BEGIN__', 'おいしい', 'ビール'],\n",
       " ['おいしい', 'ビール', 'を'],\n",
       " ['ビール', 'を', '飲も'],\n",
       " ['を', '飲も', 'う'],\n",
       " ['飲も', 'う', '__END__']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "BEGIN = '__BEGIN__'\n",
    "END = '__END__'\n",
    "\n",
    "sentence = 'おいしいビールを飲もう'\n",
    "\n",
    "t = Tokenizer()\n",
    "words = t.tokenize(sentence, wakati=True)\n",
    "words = [BEGIN] + words + [END]\n",
    "\n",
    "three_words_list = []\n",
    "for i in range(len(words) - 2):\n",
    "    three_words_list.append(words[i:i+3])\n",
    "three_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('__BEGIN__', 'おいしい', 'ビール'): 2,\n",
       "         ('おいしい', 'ビール', 'を'): 1,\n",
       "         ('ビール', 'を', '飲も'): 2,\n",
       "         ('を', '飲も', 'う'): 2,\n",
       "         ('飲も', 'う', '__END__'): 2,\n",
       "         ('__BEGIN__', 'ビール', 'を'): 1,\n",
       "         ('おいしい', 'ビール', 'は'): 1,\n",
       "         ('ビール', 'は', '生'): 1,\n",
       "         ('は', '生', '__END__'): 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_three_words_list(sentence):\n",
    "    \"\"\"文章を３単語の組にして返す\"\"\"\n",
    "    t = Tokenizer()\n",
    "    words = t.tokenize(sentence, wakati=True)\n",
    "    words = [BEGIN] + words + [END]\n",
    "    three_words_list = []\n",
    "    for i in range(len(words) - 2):\n",
    "        three_words_list.append(tuple(words[i:i+3]))\n",
    "    return three_words_list\n",
    "    \n",
    "sentences = ['おいしいビールを飲もう', 'ビールを飲もう', 'おいしいビールは生']\n",
    "three_words_list = []\n",
    "for sentence in sentences:\n",
    "    three_words_list += get_three_words_list(sentence)\n",
    "three_words_count = Counter(three_words_list)\n",
    "three_words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('__BEGIN__', 'おいしい'): {'words': ['ビール'], 'weights': [2]},\n",
       " ('おいしい', 'ビール'): {'words': ['を', 'は'], 'weights': [1, 1]},\n",
       " ('ビール', 'を'): {'words': ['飲も'], 'weights': [2]},\n",
       " ('を', '飲も'): {'words': ['う'], 'weights': [2]},\n",
       " ('飲も', 'う'): {'words': ['__END__'], 'weights': [2]},\n",
       " ('__BEGIN__', 'ビール'): {'words': ['を'], 'weights': [1]},\n",
       " ('ビール', 'は'): {'words': ['生'], 'weights': [1]},\n",
       " ('は', '生'): {'words': ['__END__'], 'weights': [1]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_markov_dict(three_words_count):\n",
    "    \"\"\"マルコフ連鎖での文章生成用の辞書データを生成する\"\"\"\n",
    "    markov_dict = {}\n",
    "    for three_words, count in three_words_count.items():\n",
    "        two_words = three_words[:2]\n",
    "        next_word = three_words[2]\n",
    "        if two_words not in markov_dict:\n",
    "            markov_dict[two_words] = {'words': [], 'weights': []}\n",
    "        markov_dict[two_words]['words'].append(next_word)\n",
    "        markov_dict[two_words]['weights'].append(count)\n",
    "    return markov_dict\n",
    "markov_dict = generate_markov_dict(three_words_count)\n",
    "markov_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'あ': 2, 'え': 2, 'い': 1, 'う': 1, 'お': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'あえいうえおあお'\n",
    "d = {}\n",
    "for char in sentence:\n",
    "    if char in d:\n",
    "        d[char] += 1\n",
    "    else:\n",
    "        d[char] = 1\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'あ': 2, 'え': 2, 'い': 1, 'う': 1, 'お': 2})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "sentence = 'あえいうえおあお'\n",
    "dd = defaultdict(int)\n",
    "for char in sentence:\n",
    "    dd[char] += 1\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'おいしい': 2, 'ビール': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_first_word_and_count(three_words_count):\n",
    "    \"\"\"最初の単語を選択するための辞書データを作成する\"\"\"\n",
    "    first_word_count = defaultdict(int)\n",
    "    \n",
    "    for three_words, count in three_words_count.items():\n",
    "        if three_words[0] == BEGIN:\n",
    "            next_word = three_words[1]\n",
    "            first_word_count[next_word] += count\n",
    "    return first_word_count\n",
    "\n",
    "get_first_word_and_count(three_words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['おいしい', 'ビール'], [2, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_first_words_weights(three_words_count):\n",
    "    \"\"\"最初の単語と重みのリストを作成する\"\"\"\n",
    "    first_word_count = get_first_word_and_count(three_words_count)\n",
    "    words = []\n",
    "    weights = []\n",
    "    for word, count in first_word_count.items():\n",
    "        words.append(word)\n",
    "        weights.append(count)\n",
    "    \n",
    "    return words, weights\n",
    "\n",
    "first_words, first_weights = get_first_words_weights(three_words_count)\n",
    "first_words, first_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_text(first_words, first_weights, markov_dict):\n",
    "    \"\"\"入力された辞書データを元に文章を生成する\"\"\"\n",
    "    first_word = random.choices(first_words, weights=first_weights)[0]\n",
    "    generate_words = [BEGIN, first_word]\n",
    "    while True:\n",
    "        pair = tuple(generate_words[-2:])\n",
    "        words = markov_dict[pair]['words']\n",
    "        weights = markov_dict[pair]['weights']\n",
    "        next_word = random.choices(words, weights=weights)[0]\n",
    "        if next_word == END:\n",
    "            break\n",
    "        generate_words.append(next_word)\n",
    "    return '' .join(generate_words[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "おいしいビールを飲もう\n",
      "ビールを飲もう\n",
      "おいしいビールは生\n",
      "おいしいビールを飲もう\n",
      "おいしいビールを飲もう\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    text = generate_text(first_words, first_weights, markov_dict)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.aozora.gr.jp/cards/000035/files/301_ruby_5915.zip'\n",
    "r = requests.get(url)\n",
    "content = r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ningen_shikkaku.txt']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import zipfile\n",
    "\n",
    "f = io.BytesIO(content)\n",
    "zipf = zipfile.ZipFile(f)\n",
    "namelist = zipf.namelist()\n",
    "namelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人間失格\r\n",
      "太宰治\r\n",
      "\r\n",
      "-------------------------------------------------------\r\n",
      "【テキスト中に現れる記号について】\r\n",
      "\r\n",
      "《》：ルビ\r\n",
      "（例）従姉妹《いとこ》\r\n",
      "\r\n",
      "｜：ルビの付く文字列の始まりを特定する記号\r\n",
      "（例）昔｜気質《かたぎ》\r\n",
      "\r\n",
      "［＃］：入力者注　主に外字の説明や、傍点の位置の指定\r\n",
      "（例）［＃３字下げ］はしがき［＃「はしがき」は大見出し］\r\n",
      "-------------------------------------------------------\r\n",
      "\r\n",
      "［＃３字下げ］はしがき［＃「はしがき」は大見出し］\r\n",
      "\r\n",
      "\r\n",
      "　私は、その男の写真を三葉、見たことがある。\r\n",
      "　一葉は、その男の、幼年時代、とでも言うべきであろうか、十歳前後かと推定される頃の写真であって、その子供が大勢の女のひとに取りかこまれ、（それは、その子供の姉たち、妹たち、それから、従姉妹《いとこ》たちかと想像される）庭園の池のほとりに、荒い縞の袴《はかま》をはいて立ち、首を三十度ほど左に傾け、醜く笑っている写真である。醜く？　けれども、鈍い人たち（\n"
     ]
    }
   ],
   "source": [
    "data = zipf.read(namelist[0])\n",
    "original_text = data.decode('Shift_JIS')\n",
    "print(original_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文の数： 1177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['私は、その男の写真を三葉、見たことがある',\n",
       " '一葉は、その男の、幼年時代、とでも言うべきであろうか、十歳前後かと推定される頃の写真であって、その子供が大勢の女のひとに取りかこまれ、（それは、その子供の姉たち、妹たち、それから、従姉妹たちかと想像される）庭園の池のほとりに、荒い縞の袴をはいて立ち、首を三十度ほど左に傾け、醜く笑っている写真である',\n",
       " '醜く？けれども、鈍い人たち（つまり、美醜などに関心を持たぬ人たち）は、面白くも何とも無いような顔をして、「可愛い坊ちゃんですね」といい加減なお世辞を言っても、まんざら空お世辞に聞えないくらいの、謂わば通俗の「可愛らしさ」みたいな影もその子供の笑顔に無いわけではないのだが、しかし、いささかでも、美醜に就いての訓練を経て来たひとなら、ひとめ見てすぐ、「なんて、いやな子供だ」と頗る不快そうに呟き、毛虫でも払いのける時のような手つきで、その写真をほうり投げるかも知れない',\n",
       " 'まったく、その子供の笑顔は、よく見れば見るほど、何とも知れず、イヤな薄気味悪いものが感ぜられて来る',\n",
       " 'どだい、それは、笑顔でない',\n",
       " 'この子は、少しも笑ってはいないのだ',\n",
       " 'その証拠には、この子は、両方のこぶしを固く握って立っている',\n",
       " '人間は、こぶしを固く握りながら笑えるものでは無いのである',\n",
       " '猿だ',\n",
       " '猿の笑顔だ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "first_sentence = '私は、その男の写真を三葉、見たことがある。'\n",
    "last_sentence = '神様みたいないい子でした'\n",
    "_, text = original_text.split(first_sentence)\n",
    "text, _ = text.split(last_sentence)\n",
    "text = first_sentence + text + last_sentence\n",
    "\n",
    "text = text.replace('|', '').replace('　', '')\n",
    "text = re.sub('《\\w+》', '', text)\n",
    "text = re.sub('［#\\w+］', '', text)\n",
    "text = text.replace('\\r', '').replace('\\n', '')\n",
    "text = re.sub('［、「」？］', '', text)\n",
    "text = re.sub('（\\w+）', '', text)\n",
    "text = re.sub('［\\w+］', '', text)\n",
    "\n",
    "sentences = text.split('。')\n",
    "print('文の数：', len(sentences))\n",
    "sentences[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [00:55<00:00, 21.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32236"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "three_words_list = []\n",
    "for sentence in tqdm(sentences):\n",
    "    three_words_list += get_three_words_list(sentence)\n",
    "three_words_count = Counter(three_words_list)\n",
    "len(three_words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19350\n",
      "447\n"
     ]
    }
   ],
   "source": [
    "markov_dict = generate_markov_dict(three_words_count)\n",
    "print(len(markov_dict))\n",
    "first_words, first_weights = get_first_words_weights(three_words_count)\n",
    "print(len(first_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "しかも、それから、ロイドの映画がその海と桜の中学校を自分は慄然としてしまったのでした\n",
      "何という失敗、自分に何の事ではないでしょうか\n",
      "「お宅は、団体生活というものを食べた記憶は、ほとんど半狂乱になったのであるが、ひび割れてしまったのだ\n",
      "ただ、みすぼらしい、貧乏くさい女だったと思うように、かえって大カフエのお店に坐っておられなくなるのは、自分の漫画も、くだものも、その用事をいちども覚えようとしたら？罪と祈り、罪の対語は、俗な言い方ですけど）その時、ふとマダムは口調を改め、あなたのほうが風がわりで面白い遊びだから、こんな貧乏くさい女には、最も気のきく」おじさんが遊び相手として附合って救われるのは、素直に今迄のからだもその頃には、自分の若白髪は、いったいどうなんだぜ」こんな、貧乏なのですが、とにかく引受けてくれている人間の女性のほうから、自分はたいてい、おっかなびっくりで、思い切って、そのような権利を留保しても、なかなか治癒し難い傷でした\n",
      "すぐ近所であったから、思いがけぬ恩を受けて、必ずすぐにそれをこそ挙げるべきだ」彼はその遊戯を当時、ハロルド・ロイドとかいう外国の遊戯場みたいにごまかしながら鮨を食わせる店というところにこそ罪が重なり、苦悩が増大し強烈になるようですが、法律とは言えませんし、ただ神の笞を受ける、そのとおりに、すぐ外出しなければならないのだ」「泣きました\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    sentence = generate_text(first_words, first_weights, markov_dict)\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('markov-dict.pickle', 'wb') as f:\n",
    "    data = (first_words, first_weights, markov_dict)\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
